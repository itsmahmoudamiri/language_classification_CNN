{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87842355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2400 images belonging to 3 classes.\n",
      "Found 600 images belonging to 3 classes.\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mamir\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m247s\u001b[0m 3s/step - accuracy: 0.5781 - loss: 1.1774 - val_accuracy: 0.6383 - val_loss: 1.0707 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 3s/step - accuracy: 0.7874 - loss: 0.5789 - val_accuracy: 0.8000 - val_loss: 0.6074 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 3s/step - accuracy: 0.8458 - loss: 0.4252 - val_accuracy: 0.8150 - val_loss: 0.4927 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 3s/step - accuracy: 0.8705 - loss: 0.3413 - val_accuracy: 0.8500 - val_loss: 0.4089 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 3s/step - accuracy: 0.8673 - loss: 0.3794 - val_accuracy: 0.4567 - val_loss: 2.5073 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 3s/step - accuracy: 0.8815 - loss: 0.2897 - val_accuracy: 0.5683 - val_loss: 1.9009 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 3s/step - accuracy: 0.8737 - loss: 0.3122 - val_accuracy: 0.8233 - val_loss: 0.4405 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 3s/step - accuracy: 0.8923 - loss: 0.3004 - val_accuracy: 0.8683 - val_loss: 0.3772 - learning_rate: 2.0000e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 3s/step - accuracy: 0.9101 - loss: 0.2590 - val_accuracy: 0.8417 - val_loss: 0.3898 - learning_rate: 2.0000e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 3s/step - accuracy: 0.9090 - loss: 0.2428 - val_accuracy: 0.8600 - val_loss: 0.3680 - learning_rate: 2.0000e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 3s/step - accuracy: 0.9014 - loss: 0.2538 - val_accuracy: 0.8617 - val_loss: 0.3372 - learning_rate: 2.0000e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m360s\u001b[0m 5s/step - accuracy: 0.9102 - loss: 0.2192 - val_accuracy: 0.8583 - val_loss: 0.3902 - learning_rate: 2.0000e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 3s/step - accuracy: 0.9151 - loss: 0.2389 - val_accuracy: 0.8850 - val_loss: 0.3189 - learning_rate: 2.0000e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m305s\u001b[0m 4s/step - accuracy: 0.9090 - loss: 0.2405 - val_accuracy: 0.8817 - val_loss: 0.3459 - learning_rate: 2.0000e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m254s\u001b[0m 3s/step - accuracy: 0.9110 - loss: 0.2457 - val_accuracy: 0.8617 - val_loss: 0.3560 - learning_rate: 2.0000e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m253s\u001b[0m 3s/step - accuracy: 0.9189 - loss: 0.2157 - val_accuracy: 0.8583 - val_loss: 0.3652 - learning_rate: 2.0000e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m250s\u001b[0m 3s/step - accuracy: 0.9122 - loss: 0.2265 - val_accuracy: 0.8617 - val_loss: 0.3185 - learning_rate: 4.0000e-05\n",
      "Epoch 18/20\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m253s\u001b[0m 3s/step - accuracy: 0.9201 - loss: 0.2167 - val_accuracy: 0.8583 - val_loss: 0.3199 - learning_rate: 4.0000e-05\n",
      "Epoch 19/20\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 3s/step - accuracy: 0.9282 - loss: 0.2021 - val_accuracy: 0.8667 - val_loss: 0.3438 - learning_rate: 4.0000e-05\n",
      "Epoch 20/20\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 3s/step - accuracy: 0.9199 - loss: 0.2266 - val_accuracy: 0.8600 - val_loss: 0.3453 - learning_rate: 4.0000e-05\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 2s/step - accuracy: 0.8829 - loss: 0.3166\n",
      "Test accuracy: 0.87\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class ImageClassifier:\n",
    "    def __init__(self, base_path, image_size=(224, 224), batch_size=32, epochs=20, num_classes=3):\n",
    "        self.base_path = base_path\n",
    "        self.image_size = image_size\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.num_classes = num_classes\n",
    "        self.train_datagen = ImageDataGenerator(\n",
    "            rescale=1./255,\n",
    "            rotation_range=20,\n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,\n",
    "            horizontal_flip=True,\n",
    "            validation_split=0.2\n",
    "        )\n",
    "\n",
    "    def build_model(self):\n",
    "        base_model = VGG16(weights='imagenet', include_top=False, input_shape=self.image_size + (3,))\n",
    "        for layer in base_model.layers:\n",
    "            layer.trainable = False\n",
    "        \n",
    "        x = Flatten()(base_model.output)\n",
    "        x = Dense(256, activation='relu')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        x = Dense(128, activation='relu')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        predictions = Dense(self.num_classes, activation='softmax')(x)\n",
    "        \n",
    "        model = Model(inputs=base_model.input, outputs=predictions)\n",
    "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "        return model\n",
    "\n",
    "    def train_and_evaluate(self):\n",
    "        train_generator = self.train_datagen.flow_from_directory(\n",
    "            self.base_path,\n",
    "            target_size=self.image_size,\n",
    "            batch_size=self.batch_size,\n",
    "            class_mode='categorical',\n",
    "            subset='training'\n",
    "        )\n",
    "\n",
    "        validation_generator = self.train_datagen.flow_from_directory(\n",
    "            self.base_path,\n",
    "            target_size=self.image_size,\n",
    "            batch_size=self.batch_size,\n",
    "            class_mode='categorical',\n",
    "            subset='validation'\n",
    "        )\n",
    "\n",
    "        model = self.build_model()\n",
    "\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "        reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.00001)\n",
    "\n",
    "        model.fit(\n",
    "            train_generator,\n",
    "            epochs=self.epochs,\n",
    "            validation_data=validation_generator,\n",
    "            callbacks=[early_stopping, reduce_lr]\n",
    "        )\n",
    "\n",
    "        # Evaluate the model\n",
    "        test_loss, test_accuracy = model.evaluate(validation_generator)\n",
    "        print(f\"Test accuracy: {test_accuracy:.2f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    base_path = \"./processed_data\"\n",
    "    classifier = ImageClassifier(base_path)\n",
    "    classifier.train_and_evaluate()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
